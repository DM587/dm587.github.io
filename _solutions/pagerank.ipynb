{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "np.set_printoptions(precision=3,suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.    0.    0.    0.5   0.    0.   ]\n",
      " [0.    0.    1.    0.5   0.333 0.5  ]\n",
      " [0.    1.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.333 0.   ]\n",
      " [0.    0.    0.    0.    0.    0.5  ]\n",
      " [0.    0.    0.    0.    0.333 0.   ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1=np.array([[1,0,0,1/2,0,0],[0,0,1,1/2,1/3,1/2],[0,1,0,0,0,0],[0,0,0,0,1/3,0],[0,0,0,0,0,1/2],[0,0,0,0,1/3,0]])\n",
    "print(A1)\n",
    "la.det(A1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A$ is a stochastic matrix because all its columns sum up to 1. We apply the Power method to see where the Markov chain converges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if it starts at page 6 and takes an even number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.    0.707 0.    0.    0.707 0.   ]\n",
      "[0.    0.289 0.866 0.289 0.    0.289]\n",
      "[0.12  0.956 0.239 0.    0.12  0.   ]\n",
      "[0.119 0.278 0.952 0.04  0.    0.04 ]\n",
      "[0.134 0.954 0.267 0.    0.019 0.   ]\n",
      "[0.133 0.273 0.953 0.006 0.    0.006]\n",
      "[0.136 0.953 0.271 0.    0.003 0.   ]\n",
      "[0.136 0.272 0.953 0.001 0.    0.001]\n",
      "[0.136 0.953 0.272 0.    0.001 0.   ]\n",
      "[0.136 0.272 0.953 0.    0.    0.   ]\n",
      "[0.136 0.953 0.272 0.    0.    0.   ]\n",
      "[0.136 0.272 0.953 0.    0.    0.   ]\n",
      "[0.136 0.953 0.272 0.    0.    0.   ]\n",
      "[0.136 0.272 0.953 0.    0.    0.   ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.7, 0. , 0. , 0. ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Power method with Euclidean (L_2 norm) Scaling:\n",
    "x_0=np.array([0,0,0,0,0,1])\n",
    "x_n=x_0\n",
    "for i in range(14):\n",
    "    x_n = np.dot(A1,x_n)\n",
    "    x_n = x_n/np.linalg.norm(x_n,ord=2)\n",
    "    print(x_n)\n",
    "x_n/np.linalg.norm(x_n,1) # we mormalise to obtain again probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.5 0.  0.  0.5 0. ]\n",
      "[0.    0.167 0.5   0.167 0.    0.167]\n",
      "[0.083 0.667 0.167 0.    0.083 0.   ]\n",
      "[0.083 0.194 0.667 0.028 0.    0.028]\n",
      "[0.097 0.694 0.194 0.    0.014 0.   ]\n",
      "[0.097 0.199 0.694 0.005 0.    0.005]\n",
      "[0.1   0.699 0.199 0.    0.002 0.   ]\n",
      "[0.1   0.2   0.699 0.001 0.    0.001]\n",
      "[0.1 0.7 0.2 0.  0.  0. ]\n",
      "[0.1 0.2 0.7 0.  0.  0. ]\n",
      "[0.1 0.7 0.2 0.  0.  0. ]\n",
      "[0.1 0.2 0.7 0.  0.  0. ]\n",
      "[0.1 0.7 0.2 0.  0.  0. ]\n",
      "[0.1 0.2 0.7 0.  0.  0. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.7, 0. , 0. , 0. ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Power method with sum (L_1 norm) Scaling:\n",
    "x_0=np.array([0,0,0,0,0,1])\n",
    "x_n=x_0\n",
    "for i in range(14):\n",
    "    x_n = np.dot(A1,x_n)\n",
    "    x_n = x_n/np.linalg.norm(x_n,ord=1)\n",
    "    print(x_n)\n",
    "x_n # /np.linalg.norm(x_n,1) # we do not need to normalise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 1. 0.]\n",
      "[0.    0.333 1.    0.333 0.    0.333]\n",
      "[0.125 1.    0.25  0.    0.125 0.   ]\n",
      "[0.125 0.292 1.    0.042 0.    0.042]\n",
      "[0.14 1.   0.28 0.   0.02 0.  ]\n",
      "[0.14  0.287 1.    0.007 0.    0.007]\n",
      "[0.142 1.    0.285 0.    0.003 0.   ]\n",
      "[0.142 0.286 1.    0.001 0.    0.001]\n",
      "[0.143 1.    0.286 0.    0.001 0.   ]\n",
      "[0.143 0.286 1.    0.    0.    0.   ]\n",
      "[0.143 1.    0.286 0.    0.    0.   ]\n",
      "[0.143 0.286 1.    0.    0.    0.   ]\n",
      "[0.143 1.    0.286 0.    0.    0.   ]\n",
      "[0.143 0.286 1.    0.    0.    0.   ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.7, 0. , 0. , 0. ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Power method with maximum entry (L_\\infty norm) Scaling:\n",
    "x_0=np.array([0,0,0,0,0,1])\n",
    "x_n=x_0\n",
    "for i in range(14):\n",
    "    x_n = np.dot(A1,x_n)\n",
    "    x_n = x_n/np.linalg.norm(x_n,ord=np.inf)\n",
    "    print(x_n)\n",
    "x_n/np.linalg.norm(x_n,1) # we need to normalise to obtain probabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization is useful to avoid numbers growing large and creating numerical problems. However, since the dominant eigenvalue of a stochastic matrix is never larger than one, we can also skip the normalization throughout the iterations in our specific case.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.5 0.  0.  0.5 0. ]\n",
      "[0.    0.167 0.5   0.167 0.    0.167]\n",
      "[0.083 0.667 0.167 0.    0.083 0.   ]\n",
      "[0.083 0.194 0.667 0.028 0.    0.028]\n",
      "[0.097 0.694 0.194 0.    0.014 0.   ]\n",
      "[0.097 0.199 0.694 0.005 0.    0.005]\n",
      "[0.1   0.699 0.199 0.    0.002 0.   ]\n",
      "[0.1   0.2   0.699 0.001 0.    0.001]\n",
      "[0.1 0.7 0.2 0.  0.  0. ]\n",
      "[0.1 0.2 0.7 0.  0.  0. ]\n",
      "[0.1 0.7 0.2 0.  0.  0. ]\n",
      "[0.1 0.2 0.7 0.  0.  0. ]\n",
      "[0.1 0.7 0.2 0.  0.  0. ]\n",
      "[0.1 0.2 0.7 0.  0.  0. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.7, 0. , 0. , 0. ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0=np.array([0,0,0,0,0,1])\n",
    "x_n=x_0\n",
    "for i in range(14):\n",
    "    x_n = np.dot(A1,x_n)\n",
    "    print(x_n)\n",
    "x_n/np.linalg.norm(x_n,1) # we need to normalise to obtain probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_method(A, x_0, niter, scaling=2):\n",
    "    x_n=x_0/np.linalg.norm(x_0,scaling)\n",
    "    for i in range(niter):\n",
    "        x_n = np.dot(A,x_n)\n",
    "        x_n = x_n/np.linalg.norm(x_n,ord=scaling)\n",
    "        print(x_n)\n",
    "    x_n = x_n/np.linalg.norm(x_n,ord=1) # we mormalise to obtain again probabilities\n",
    "    return x_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if it starts at page 6 and takes an odd number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.    0.707 0.    0.    0.707 0.   ]\n",
      "[0.    0.289 0.866 0.289 0.    0.289]\n",
      "[0.12  0.956 0.239 0.    0.12  0.   ]\n",
      "[0.119 0.278 0.952 0.04  0.    0.04 ]\n",
      "[0.134 0.954 0.267 0.    0.019 0.   ]\n",
      "[0.133 0.273 0.953 0.006 0.    0.006]\n",
      "[0.136 0.953 0.271 0.    0.003 0.   ]\n",
      "[0.136 0.272 0.953 0.001 0.    0.001]\n",
      "[0.136 0.953 0.272 0.    0.001 0.   ]\n",
      "[0.136 0.272 0.953 0.    0.    0.   ]\n",
      "[0.136 0.953 0.272 0.    0.    0.   ]\n",
      "[0.136 0.272 0.953 0.    0.    0.   ]\n",
      "[0.136 0.953 0.272 0.    0.    0.   ]\n",
      "[0.136 0.272 0.953 0.    0.    0.   ]\n",
      "[0.136 0.953 0.272 0.    0.    0.   ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.7, 0.2, 0. , 0. , 0. ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0=np.array([0,0,0,0,0,1])\n",
    "power_method(A1,x_0,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if it starts at page 4 and takes an even number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.707 0.707 0.    0.    0.    0.   ]\n",
      "[0.707 0.    0.707 0.    0.    0.   ]\n",
      "[0.707 0.707 0.    0.    0.    0.   ]\n",
      "[0.707 0.    0.707 0.    0.    0.   ]\n",
      "[0.707 0.707 0.    0.    0.    0.   ]\n",
      "[0.707 0.    0.707 0.    0.    0.   ]\n",
      "[0.707 0.707 0.    0.    0.    0.   ]\n",
      "[0.707 0.    0.707 0.    0.    0.   ]\n",
      "[0.707 0.707 0.    0.    0.    0.   ]\n",
      "[0.707 0.    0.707 0.    0.    0.   ]\n",
      "[0.707 0.707 0.    0.    0.    0.   ]\n",
      "[0.707 0.    0.707 0.    0.    0.   ]\n",
      "[0.707 0.707 0.    0.    0.    0.   ]\n",
      "[0.707 0.    0.707 0.    0.    0.   ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.5, 0. , 0.5, 0. , 0. , 0. ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0=np.array([0,0,0,1,0,0])\n",
    "power_method(A1, x_0, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if it starts at page 4 and takes an odd number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.707 0.707 0.    0.    0.    0.   ]\n",
      "[0.707 0.    0.707 0.    0.    0.   ]\n",
      "[0.707 0.707 0.    0.    0.    0.   ]\n",
      "[0.707 0.    0.707 0.    0.    0.   ]\n",
      "[0.707 0.707 0.    0.    0.    0.   ]\n",
      "[0.707 0.    0.707 0.    0.    0.   ]\n",
      "[0.707 0.707 0.    0.    0.    0.   ]\n",
      "[0.707 0.    0.707 0.    0.    0.   ]\n",
      "[0.707 0.707 0.    0.    0.    0.   ]\n",
      "[0.707 0.    0.707 0.    0.    0.   ]\n",
      "[0.707 0.707 0.    0.    0.    0.   ]\n",
      "[0.707 0.    0.707 0.    0.    0.   ]\n",
      "[0.707 0.707 0.    0.    0.    0.   ]\n",
      "[0.707 0.    0.707 0.    0.    0.   ]\n",
      "[0.707 0.707 0.    0.    0.    0.   ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 0. , 0. , 0. , 0. ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0=np.array([0,0,0,1,0,0])\n",
    "power_method(A1, x_0, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the Markov process does not converge. \n",
    "\n",
    "Remember that:\n",
    "a Markov chain converges to a steady-state vector $\\vec x$, if $A$ is a positive\n",
    "stochastic matrix in which case $\\lambda_1=1$ is a unique dominant eigenvalue of $A$.\n",
    "\n",
    "Let's have a look at the eigenvalues of the transition matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EigResult(eigenvalues=array([ 1.   ,  1.   , -1.   ,  0.   ,  0.408, -0.408]), eigenvectors=array([[ 1.   ,  0.   ,  0.   , -0.408, -0.308, -0.173],\n",
       "       [ 0.   ,  0.707, -0.707,  0.   , -0.251,  0.141],\n",
       "       [ 0.   ,  0.707,  0.707, -0.408, -0.615, -0.346],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.816,  0.364,  0.487],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.446, -0.597],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.364,  0.487]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.eig(A1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three eigenvalues with absolute value equal to 1, ie, $|\\lambda_i|=1, i=1,2,3$. In general, a stochastic matrix has a dominant eigenvalue equal to one but not in this case. \n",
    "\n",
    "A stochastic matrix has the following properties.\n",
    "The largest absolute value of a stochastic matrix is at most 1 by Gershgorin circle theorem (not discussed in class). Additionally, every stochastic matrix has an \"obvious\" column eigenvector associated to the eigenvalue 1: the vector ${\\boldsymbol {1}}$, whose coordinates are all equal to 1. \n",
    "\n",
    "On the other hand, Perron theorem applied to stochastic matrices tells us that\n",
    "if the stochastic matrix is positive then it has a dominant eigenvalue $\\lambda\n",
    "= 1$. More generally, Frobenius theorem tells us that if the stochastic matrix\n",
    "is nonnegative and irreducible (there is a non-zero probability of\n",
    "transitioning, even if in more than one step, from any state to any other state)\n",
    "then again it has a dominant eigenvalue\n",
    "$\\lambda = 1$. However, in general stochastic matrices need not be positive or\n",
    "irreducible. (See [here](https://en.wikipedia.org/wiki/Perron%E2%80%93Frobenius_theorem#Classification_of_matrices)\n",
    "for more details and precise definitions of these matrices).\n",
    "\n",
    "In the next subtask we try to modify the transition matrix such that it has all entries positive (no zeros) such that Perron's theorem applies and the corresponding process converges.\n",
    "\n",
    "A Markov process with transition matrix $A$ is said to be *regular* if all the entries of some power of $A$ are positive. It can be shown that if this happens the $A$ has a dominant eigenvalue equal to 1 as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.167, 0.167, 0.167, 0.167, 0.167, 0.167],\n",
       "       [0.167, 0.167, 0.167, 0.167, 0.167, 0.167],\n",
       "       [0.167, 0.167, 0.167, 0.167, 0.167, 0.167],\n",
       "       [0.167, 0.167, 0.167, 0.167, 0.167, 0.167],\n",
       "       [0.167, 0.167, 0.167, 0.167, 0.167, 0.167],\n",
       "       [0.167, 0.167, 0.167, 0.167, 0.167, 0.167]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2 = 1/6*np.ones((6,6))\n",
    "A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.408 0.408 0.408 0.408 0.408 0.408]\n",
      "[0.408 0.408 0.408 0.408 0.408 0.408]\n",
      "[0.408 0.408 0.408 0.408 0.408 0.408]\n",
      "[0.408 0.408 0.408 0.408 0.408 0.408]\n",
      "[0.408 0.408 0.408 0.408 0.408 0.408]\n",
      "[0.408 0.408 0.408 0.408 0.408 0.408]\n",
      "[0.408 0.408 0.408 0.408 0.408 0.408]\n",
      "[0.408 0.408 0.408 0.408 0.408 0.408]\n",
      "[0.408 0.408 0.408 0.408 0.408 0.408]\n",
      "[0.408 0.408 0.408 0.408 0.408 0.408]\n",
      "[0.408 0.408 0.408 0.408 0.408 0.408]\n",
      "[0.408 0.408 0.408 0.408 0.408 0.408]\n",
      "[0.408 0.408 0.408 0.408 0.408 0.408]\n",
      "[0.408 0.408 0.408 0.408 0.408 0.408]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.167, 0.167, 0.167, 0.167, 0.167, 0.167])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0=np.array([0,0,0,1,0,0])\n",
    "x=power_method(A2,x_0,niter=14)\n",
    "x/np.linalg.norm(x,ord=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1., -0.,  0.,  0.,  0.,  0.]),\n",
       " array([[ 0.408, -0.517,  0.   , -0.   ,  0.   ,  0.   ],\n",
       "        [ 0.408,  0.841,  0.894, -0.765,  0.   ,  0.   ],\n",
       "        [ 0.408, -0.081, -0.224,  0.64 , -0.   , -0.   ],\n",
       "        [ 0.408, -0.081, -0.224,  0.041, -0.577, -0.577],\n",
       "        [ 0.408, -0.081, -0.224,  0.041,  0.789, -0.211],\n",
       "        [ 0.408, -0.081, -0.224,  0.041, -0.211,  0.789]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ell, P = la.eig(A2)\n",
    "ell, P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix is positive hence it has a dominant eigenvalue equal to 1. The corresponding eigenvector is a vector of entries of 1 or normalized as in the matrix P above.\n",
    "\n",
    "If we can calculate the eigenvalues because computationally feasibile as in these small examples, we can also find the steady-state vectors by applying the theory seen on slide 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.167 0.167 0.167 0.167 0.167 0.167]\n"
     ]
    }
   ],
   "source": [
    "P_inv = la.inv(P) # this is also computationally demanding\n",
    "z_0 = P_inv @ x_0\n",
    "x_n = z_0[0] * P[:,0]\n",
    "print(x_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 0.85 * A1 + 0.15 * A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.705 0.705 0.039 0.039 0.039 0.039]\n",
      "[0.707 0.126 0.689 0.054 0.06  0.054]\n",
      "[0.682 0.707 0.153 0.061 0.067 0.061]\n",
      "[0.681 0.256 0.676 0.065 0.072 0.065]\n",
      "[0.654 0.699 0.264 0.066 0.073 0.066]\n",
      "[0.649 0.358 0.66  0.068 0.076 0.068]\n",
      "[0.626 0.686 0.35  0.068 0.076 0.068]\n",
      "[0.62  0.433 0.642 0.07  0.077 0.07 ]\n",
      "[0.602 0.672 0.413 0.069 0.077 0.069]\n",
      "[0.596 0.486 0.626 0.07  0.078 0.07 ]\n",
      "[0.582 0.659 0.459 0.07  0.078 0.07 ]\n",
      "[0.577 0.524 0.613 0.071 0.078 0.071]\n",
      "[0.567 0.649 0.492 0.07  0.078 0.07 ]\n",
      "[0.563 0.551 0.603 0.071 0.078 0.071]\n",
      "[0.555 0.641 0.515 0.07  0.078 0.07 ]\n",
      "[0.552 0.57  0.595 0.071 0.078 0.071]\n",
      "[0.546 0.635 0.531 0.07  0.078 0.07 ]\n",
      "[0.544 0.584 0.59  0.071 0.078 0.071]\n",
      "[0.539 0.631 0.543 0.07  0.078 0.07 ]\n",
      "[0.538 0.593 0.585 0.071 0.078 0.071]\n",
      "[0.535 0.627 0.552 0.071 0.078 0.071]\n",
      "[0.533 0.6   0.582 0.071 0.078 0.071]\n",
      "[0.531 0.625 0.558 0.071 0.078 0.071]\n",
      "[0.53  0.605 0.58  0.071 0.078 0.071]\n",
      "[0.529 0.623 0.562 0.071 0.078 0.071]\n",
      "[0.528 0.609 0.578 0.071 0.078 0.071]\n",
      "[0.527 0.622 0.566 0.071 0.078 0.071]\n",
      "[0.526 0.611 0.577 0.071 0.078 0.071]\n",
      "[0.526 0.621 0.568 0.071 0.078 0.071]\n",
      "[0.525 0.613 0.576 0.071 0.078 0.071]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.272, 0.317, 0.298, 0.036, 0.041, 0.036])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0=np.array([0,0,0,1,0,0])\n",
    "power_method(A,x_0,niter=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence page 2 has the highest ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.   ,  0.85 , -0.85 ,  0.347, -0.347, -0.   ]),\n",
       " array([[ 0.522,  0.816, -0.   ,  0.308, -0.173,  0.408],\n",
       "        [ 0.618, -0.408,  0.707,  0.251,  0.141, -0.   ],\n",
       "        [ 0.574, -0.408, -0.707,  0.615, -0.346,  0.408],\n",
       "        [ 0.071, -0.   , -0.   , -0.364,  0.487, -0.816],\n",
       "        [ 0.078,  0.   ,  0.   , -0.446, -0.597, -0.   ],\n",
       "        [ 0.071, -0.   , -0.   , -0.364,  0.487, -0.   ]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ell, P = la.eig(A)\n",
    "ell, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27  0.32  0.297 0.036 0.041 0.036]\n"
     ]
    }
   ],
   "source": [
    "P_inv = la.inv(P) # this is also computationally demanding\n",
    "z_0 = P_inv @ x_0\n",
    "x_n = z_0[0] * P[:,0]\n",
    "print(x_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slight discrepancies might be due to rounding erros or to an insufficient number of iterations in the power method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../assets/top250movies.txt\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = {} \n",
    "for line in lines:\n",
    "    entries = line.strip().split(\"/\")\n",
    "    db[entries[0]] = entries[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle the issue of weights due to repeated co-presences of actors in movies, we can first create a multi directed graph and then convert it in a directed graph with weights on arcs. A multi digraph is a graph that allows multiple arcs between nodes. Alternatively, as hinted by the text of the exercise we could create a adjacency dictionary where for every actor we list the actors that are reached by the first actor (ie, more expensive actors) allowing repeated entries. Then we can construct the digraph using the adjacency dictionary. However, graphs in networkx automatically construct adjacency lists and since library functions are to be preferred in Python because more efficient, we prefer to use the first alternative with multi digraph then converted in digraph.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "MDG = nx.MultiDiGraph()\n",
    "for k in db:\n",
    "    for i in range(len(db[k])):\n",
    "        actor = db[k][i]\n",
    "        MDG.add_edges_from([(cheaper_actor,actor) for cheaper_actor in db[k][(i+1):]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14882, 886259)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MDG.number_of_nodes(), MDG.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "DG = nx.DiGraph()\n",
    "for node, outgoing_neighbors in MDG.adjacency():\n",
    "    for neighbor, arc_dict in outgoing_neighbors.items():\n",
    "        value = len(arc_dict.values())\n",
    "        DG.add_edge(node, neighbor, weight = value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14882, 880639)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DG.number_of_nodes(), DG.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "PR = nx.pagerank(DG, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Leonardo DiCaprio', 'Robert De Niro', 'Tom Hanks', 'Jamie Foxx', 'Al Pacino']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(PR, key=PR.get, reverse=True)[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
